{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2 - Train a Birth-Year Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even more text predictions\n",
    "Text isn't just useful for predicting discrete classes like nationality that you did in your earlier notebook. In this second notebook, you'll develop a _regressor_ instead of a classifier to predict a person's birth year from their Wikipedia biography. Much like nationality, biographies have rich information in their description of places, years, events, or institutions that help contextualize a person's life within a time period. Regression problems are less common than classification in NLP, but can still easily be found, e.g., predicting the number of retweets for a message or predicting box office revenue from a movie's initial reviews.\n",
    "\n",
    "For this notebook, you'll use a simple regression model, `LinearRegression` but there are many more advanced (and slower) models you could try out using the `sklearn` library. Unlike in classification problems (for the most part), in regression problems, the output classes are related to each other; so, predicting a birth year of 1890 when a person was born in 1892 is wrong but _not that wrong,_ as compared to a prediction like 1442. As a result, we'll evaluate with a different metric instead of F1 here: [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error). \n",
    "\n",
    "For this notebook, you'll re-use much of your preprocessing setup that you developed in the first notebook and then sprinkle in regression specific examples. The goal is to help you again build your skills in developing machine learning pipelines for NLP. We've deliberately kept the setup simple, however, as with the first notebook, there are _many_ ways you could extend this approach to improve performance.\n",
    "\n",
    "Finally, we've included a simple error analysis at the end. As an NLP practitioner, you'll want to get in the habit of looking at your model's predictions. Do they make sense? What kind of bias does my system have? What kind errors does it make and are these systematic? The analysis you do will be simple here, but you can go much further to try to investigate what kinds of errors it's like to make (hint: try looking at some of the highly weighted features!). If you decide to do an error analysis and/or work on improving the model's performance, feel free to discuss in Slack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good practice to manually set your random seed when performing machine learning experiments so that they are reproducible for others. Here, we set our seed to 655 to ensure your models and experiments get the expected results when evaluating your homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 655"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Read in the corpus file, which is in JSON lines format (one line per JSON object). Each line represents cleaned up data a single Wikipedia article for a person. For this exercise, we'll construct a dataframe with the `bio` of the person's article (their biography) and their `birth year`. The birth year is specified as a string in the `birth_date` field of the `infobox` of the page. If someone doesn't have a birth year, you should skip their article; if someone's birthday year isn't specified as an integer, you should skip their article as well.\n",
    "\n",
    "*Important Note:* In general, it's always a good idea to look at how noisy is your text before deciding on its final form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6600ede25a6758205ea6b8f6baa89e0d",
     "grade": false,
     "grade_id": "cell-7593e718ba1935c3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "birthyear_df = pd.read_csv('assets/birth_year.tsv.gz', sep='\\t', compression='gzip')\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that you have things loaded correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.1: Print the dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4b20e2b3bed76f55d8b7ec14a860019",
     "grade": true,
     "grade_id": "data_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53470\n"
     ]
    }
   ],
   "source": [
    "print(len(birthyear_df)) # Should be 53456\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "755df8871bc445cad9c2a8a384cdaec8",
     "grade": false,
     "grade_id": "cell-8466ebbe8fa8aa74",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Task 1.2.2: Print the number of birth year labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0132eb33554883f4575ff969f3189ca9",
     "grade": true,
     "grade_id": "num_birth_year_labels",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553\n"
     ]
    }
   ],
   "source": [
    "print(len(set(birthyear_df.birth_year))) # Should be 1552\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.3: Print out the top 20 most common birth years to see what Wikipedia's labels look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc80f6a38ac901095684aac6310a1daf",
     "grade": true,
     "grade_id": "most_common_birth_years",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1954, 477),\n",
       " (1948, 477),\n",
       " (1952, 474),\n",
       " (1953, 457),\n",
       " (1957, 453),\n",
       " (1947, 453),\n",
       " (1956, 449),\n",
       " (1955, 447),\n",
       " (1950, 441),\n",
       " (1959, 439),\n",
       " (1951, 437),\n",
       " (1960, 436),\n",
       " (1958, 436),\n",
       " (1962, 422),\n",
       " (1961, 411),\n",
       " (1944, 410),\n",
       " (1946, 410),\n",
       " (1963, 410),\n",
       " (1964, 409),\n",
       " (1949, 408)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20 = Counter(birthyear_df.birth_year).most_common(20)\n",
    "#hidden tests are within this cell\n",
    "top_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Life Pro Tip: Always look at your data (always)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.4: Fix the year labels\n",
    "We won't fix _everything_ but as a quick improvement, let's bound our years. Remove rows in our dataframe where the birth year is less than -100 or greater than 2020. Put all remaining valid items in the list `clean_birthyear_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4408031aafe7b1707e2e1941c52a128f",
     "grade": false,
     "grade_id": "cell-f583802aabe1611d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.5: Print the number of items in `cleaned_items`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c35ae72480a820985e94abc5a20055dd",
     "grade": true,
     "grade_id": "num_cleaned_items",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_birthyear_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mclean_birthyear_df\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_birthyear_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(clean_birthyear_df))\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.6: Split dataset into test, train and dev\n",
    "We have a large enough dataset that we can effectively split it into train, development, and test sets, using the standard ratio of 80%, 10%, 10% for each, respectively. We'll use `split` from `numpy` to split the data into train, dev, and test separately. We'll call these `train_df`, `dev_df`, and `test_df`.  Note that `split` does not shuffle, so we'll use `DataFrame.sample()` and randomly resample our entire dataset to get a random shuffle before the split.\n",
    "\n",
    "*Important note*: Remember to set  `random_state` in `split` to our seed so that you end up with the same (random) ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df, test_df = \\\n",
    "              np.split(clean_birthyear_df.sample(frac=1, random_state=RANDOM_SEED), \n",
    "                       [int(.8*len(clean_birthyear_df)), int(.9*len(clean_birthyear_df))])\n",
    "print(len(train_df), len(dev_df), len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.7: print the `bio` of the first instance of your training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "773de37b84fcff1a079bd7cf8efb7bb1",
     "grade": true,
     "grade_id": "first_instance_train",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(train_df.iloc[0,:]['bio'])\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.8: Print the `bio` of the first instance of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e87a3877c523ec371b0a349e6e4dc49",
     "grade": true,
     "grade_id": "first_instance_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(test_df.iloc[0,:]['bio'])\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing your classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.9: Convert your text data to features\n",
    "The dataset has been prepared and the time has now arrived to actually start doing some predictions! We'll be using a `TfIdfVectorizer` to convert the text into features. There are several important things to note:\n",
    "\n",
    "1. We have a *lot* of words. There are almost too many to feasibly use unless we're running on a powerful computer. _But_ as we saw above, most words are actually relatively rare. This rarity is quite useful for us because it means we can remove these words as features to our classifier and they shouldn't affect performance too much (after all, the classifier can't learn from features that aren't present).\n",
    "2. In addition to rare words, there's generally a few very common words. These are often known as _stop words_ like \"the\". In most settings (but not all!), these features don't add much information so we can safely remove them.\n",
    "\n",
    "The [TfIdfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class thankfully provides easy ways for us to do both. We'll use `min_df` to ensure that word show up at least 50 times and use `stop_words` to specify their default `english` list. \n",
    "\n",
    "Create this `TfIdfVectorizer` and call it vectorizer. Then, call `fit_transform` on the list of biographies in  `train_df` to convert the text into a matrix of features we'll call `X_train`. `X` is the standard name you'll see for talking about the training data that is provided to a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6aaae79c18ce24c5871b2211df3e2d0b",
     "grade": false,
     "grade_id": "cell-a375d9d9029586b6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.10: Sanity Check: print the shape of X_train\n",
    "Let's ensure that we featurized everything as expected. You should have 8,864 word features in your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a75edb6e4c7abf6f5cbdd02b8e4ee981",
     "grade": true,
     "grade_id": "shape_x_train",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.11: Get the list of labels\n",
    "We need to get the final list of labels in a python `list` for sklearn to use. Create this list from `train_df` and let's call it `y_train`. `y` is normally used to refer to the label of the classifier (or value in  a regressor) in machine learning. We use the lower case here to indicate it's a vector, whereas `X` is upper case because it's a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46778edede65f7ce07511f39a0e88d3c",
     "grade": false,
     "grade_id": "cell-da1e21d5e678437e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.12: Fit the regressor on a subset of the data\n",
    "Finally, let's fit the regressor. For a start we'll use `LinearRegression` with the default parameters. To train your regressor, create a `LinearRegression` object (typically regressor are named `reg`) and call `fit` passing in `X_train` and `y_train`.\n",
    "\n",
    "For this cell, let's just use the first 10,000 rows of `X_train` and `y_train` to fit the regressor. In general, when you have a large dataset, it's useful to go end-to-end and train one of these half-baked regressor to verify that your model works as expected. You can even do some analyses if the performance is good enough to get a sense of how things are working. Then you can train on the full data.\n",
    "\n",
    "*Notes:*\n",
    "1. `X_train` is a numpy array, so you'll need to use array indexing operations to get the first 10,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70b708176c039c6df207bb1b98d57c7a",
     "grade": false,
     "grade_id": "cell-1e4e2aca7660eabf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.13: Generate dev data\n",
    "\n",
    "Let's generate the numpy matrices for the development data. Take the text in our `dev_df` and pass it through the vectorizer to turn it into features. We'll call this `X_dev`. Also create a list of the corresponding labels for each item, which we'll call `y_dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fc4f4780ead5998c2a627816c313170",
     "grade": false,
     "grade_id": "cell-43bbe211e9ef5fd1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.14: Create Dummy classifiers\n",
    "It's always important to contextualize your results by comparing it with naive regressors. If these regressors do well, then your task is easy! If not, then you can see how much better your system does at first. We'll use two different strategies using the [Dummy Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html) class. Create two `DummyRegressor` instances that use the `mean` and `median` strategies and fit these on the training data so we can compare them with our regressor that was trained on 10K instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55ff9f189343c3d3a8271f1b646f70a0",
     "grade": false,
     "grade_id": "cell-4610b34123cc760f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.15: Generate all the predictions\n",
    "Let's generate our predictions. We have three models: our `LinearRegression` model trained on 10K items and two `DummyRegressor` models that are baselines. Using our `X_dev` data, predict the birth year for each person and store these as:\n",
    "* `lr_tiny_dev_preds`\n",
    "* `mean_dev_preds`\n",
    "* `median_dev_preds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aca6abc877e5bf3852e99212da3788ca",
     "grade": false,
     "grade_id": "cell-2b37c741403af20d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.16: Score our predictions\n",
    "We'll use the [mean squared error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) (MSE) to see how close our estimates of birth year are. Calculate the MSE for each of the three models and call these `lr_mse`, `mean_mse`, and `median_mse`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d441a3ef31c223632f818d2d60b2d77",
     "grade": false,
     "grade_id": "cell-f7a3d57016809441",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dfe8cfe75267270c4cb2c8e6e59e417",
     "grade": true,
     "grade_id": "r2_scores",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(lr_mse)\n",
    "print(mean_mse)\n",
    "print(median_mse)\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, our simple classifier did not do well! :( "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.17: Fit the classifier on the full data\n",
    "Let's see if we can beat the baselines with a bit more data. Train a new `LinearRegression` model on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4e7377932e11c695d5a55318cc957eb",
     "grade": false,
     "grade_id": "cell-68ad2ec0e328c87b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.18: Generate all the predictions for the final model \n",
    "Generate predictions for the development data using our new model trained on all the data. Call the output of these `lr_dev_preds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aedaeb91a22f13cddace6b53d91bc497",
     "grade": false,
     "grade_id": "cell-b4313922a0c0f4ed",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.19:  Score the predictions\n",
    "Score the predictions for the model using `mean_squared_error` and call the output `lr_dev_mse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e17be6c17ed8e139c855024005ba6a2d",
     "grade": true,
     "grade_id": "cell-c5084e27c0c10cf6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lr_dev_mse = mean_squared_error(y_dev, lr_dev_preds)\n",
    "print(lr_dev_mse)\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that MSE with the baselines and you can see it's much better! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced NLP options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.20: Fit a unigram and bigram LinearRegression classifier\n",
    "Unigrams and Bigrams can be powerful features  for classification. Let's see if our model gets better performance if we train a new model that now includes bigrams.\n",
    "\n",
    "To start, create a new `TfidfVectorizer` and use the `ngram_range` parameter to use both unigram and bigram features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b10982f6765c6f3cc3b43066a3ae3d7",
     "grade": false,
     "grade_id": "cell-45937e0a30c349cb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.21: Print the feature matrix shape when using unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72e4038f0822ce4f48b48fe34b56fe3c",
     "grade": true,
     "grade_id": "cell-ef02cbeef4a8de49",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.22: Train the unigram and bigram classifier\n",
    "Create a new `LinearRegression` classifier model and fit it on the `X_train` and `y_train` data. Note that we don't have to recreate `y_train` since we are only changing how we featurize the text (not the labels  associated with the text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cff2f53321d3257c166218323a013ffb",
     "grade": false,
     "grade_id": "cell-3ab2d24a349490eb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the dev data\n",
    "Since we've changed how we define features, we'll need to reprocess the dev data using our new `TfIdfVectorizer`. Save this output as `X_dev` and then predict the scores using the new model, saving its predictions as `lr_dev_preds`. Finally, score the model using MSE, save this as `lr_dev_mse`, and print the MSE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c72fef1efda23a9e1f902a1a161482c",
     "grade": false,
     "grade_id": "cell-432b62a772d45a16",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b9717cf010b77fe0a566a56aaff8576",
     "grade": true,
     "grade_id": "cell-1bc71e8a312926b3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(lr_dev_mse)\n",
    "#hidden tests are within this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "Let's take a look at where our model is making some mistakes&mdash;are we doing better or worse in some situations?\n",
    "\n",
    "Start by creating a pandas data frame that has two columns: the actual birth year, with column name \"Born\", and a second column named \"Predicted\" for our model's predicted value. Call this dataframe `df` and use the data frame to compute a third column called \"Error\" that has the error of the prediction (i.e., `true_value - predicted_value` )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da8ffd408b99260016b52e6471ce718c",
     "grade": false,
     "grade_id": "cell-66ef510cac35dc39",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the joint distribution\n",
    "Let's start by seeing how the two distributions line up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=df, x='Born', y='Predicted', kind=\"hex\", color=\"#4CB391\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh! it's a bit tough to see over such a long span, but it looks like most of the people are born in later years. Let's try to zoom in a bit for the people born after 1500. Modify the plot code above in the cell below to only plot our predictions for people born after 1500. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f321900ebf15cec03e06e9ef7dd101d4",
     "grade": false,
     "grade_id": "cell-4b50ff478d647409",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's plot the error distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df.Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad distribution, but are all the errors distributed equally? Let's make a `lineplot` that shows the  relationship between two variables. What do you see in the data? What kinds of mistakes is your model likely to make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df, x='Born', y='Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_applied_natural_language_processing_v2_assignment1_part2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
